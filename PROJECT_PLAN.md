FINAL PROJECT PLAN

Fully Agentic, LLM-Only Semantic Coverage Interpretation

(DeepAgents-Orchestrated)

â¸»

ğŸ”’ Milestone A0 â€” Research Claim Lock (LLM-Only Redefinition)

AmaÃ§

â€œLLM-onlyâ€ iddiasÄ±nÄ± yanlÄ±ÅŸ anlaÅŸÄ±lmayacak ÅŸekilde tanÄ±mlamak.

YapÄ±lacaklar
â€¢ Tek cÃ¼mlelik iddia:

â€œThis work investigates whether LLM-based agents, without any hand-coded decision logic, can autonomously interpret raw execution artifacts (tests, coverage, traces) and decide how to act.â€

    â€¢	AÃ§Ä±k non-goals:
    â€¢	AST yok
    â€¢	CFG yok
    â€¢	heuristic yok
    â€¢	rule-based policy yok
    â€¢	code-driven prioritization yok
    â€¢	Net ayrÄ±m:
    â€¢	Code = sandbox + I/O
    â€¢	Agents = cognition + control

Ã‡Ä±ktÄ±lar
â€¢ docs/research_positioning.md

Kabul Kriteri
â€¢ Bir okuyucu â€œkod ne yapÄ±yor / LLM ne yapÄ±yorâ€ ayrÄ±mÄ±nÄ± net gÃ¶rÃ¼yor.

â¸»

ğŸ§± Milestone A1 â€” Blind Tool Substrate (No Intelligence)

AmaÃ§

AraÃ§lar tamamen kÃ¶r olsun.

Tools (deÄŸiÅŸtirilemez kontrat)
â€¢ run_tests() â†’ raw stdout/stderr
â€¢ read_file(path)
â€¢ read_file_window(path, start, end)
â€¢ list_files()
â€¢ log_event(payload)

â— Tools:
â€¢ coverage yorumlamaz
â€¢ missing line hesaplamaz
â€¢ context seÃ§mez
â€¢ Ã¶nem atamaz

Ã‡Ä±ktÄ±lar
â€¢ tools/
â€¢ runs/<run_id>/raw_logs.json

Kabul Kriteri
â€¢ Tool Ã§Ä±ktÄ±larÄ± tek baÅŸÄ±na hiÃ§bir anlam ifade etmiyor.

â¸»

ğŸ§  Milestone A2 â€” Agent Graph (DeepAgents Core)

AmaÃ§

Policy yerine Ã§ok-ajanlÄ± biliÅŸ.
**âš ï¸ DeepAgents Integration Note:**
DeepAgents was evaluated as a routing substrate but exhibited non-terminating internal loops even under tool-free configurations. The custom orchestrator (`custom_session.py`) was retained for experimental reproducibility. See `docs/deepagents_failure.md` for details.
Agentâ€™lar (tamamÄ± LLM) 1. Planner Agent
â€¢ â€œÅu an ne yapmalÄ±yÄ±m?â€
â€¢ Hangi tool Ã§aÄŸrÄ±lacak â†’ kendisi karar verir 2. Analysis Agent
â€¢ Ham test/coverage Ã§Ä±ktÄ±sÄ±nÄ± yorumlar
â€¢ Hipotez Ã¼retir 3. Critic Agent
â€¢ â€œBu yorum saÃ§ma mÄ±?â€
â€¢ Ã‡eliÅŸki, boÅŸluk, aÅŸÄ±rÄ± Ã¶zgÃ¼ven tespiti 4. Reflection Agent
â€¢ â€œDevam etmeli miyim?â€
â€¢ STOP kararÄ±nÄ± kendisi verir 5. Executor Agent
â€¢ Tool Ã§aÄŸrÄ±sÄ±nÄ± yapar
â€¢ Asla yorum yapmaz

DeepAgents sadece:
â€¢ mesaj akÄ±ÅŸÄ±nÄ±
â€¢ sÄ±ra kontrolÃ¼nÃ¼
â€¢ max_turn (gÃ¼venlik) sÄ±nÄ±rÄ±nÄ± yÃ¶netir

Ã‡Ä±ktÄ±lar
â€¢ agents/
â€¢ agent_graph.yaml

Kabul Kriteri
â€¢ HiÃ§bir karar koddan gelmiyor.
â€¢ AynÄ± durumda farklÄ± runâ€™lar farklÄ± strateji deneyebiliyor.

â¸»

ğŸ§¾ Milestone A3 â€” LLM-Owned Semantic Hypothesis

AmaÃ§

YapÄ± var ama zorlayÄ±cÄ± kontrol yok.

SemanticHypothesis (LLM sÃ¶zleÅŸmesi)

{
"hypothesis": "...",
"confidence_level": "LOW|MEDIUM|HIGH",
"assumptions": [...],
"evidence": [...],
"what_might_be_missing": "...",
"next_question": "..."
}

    â€¢	JSON validation: syntax only
    â€¢	Ä°Ã§erik doÄŸruluÄŸu:
    â€¢	Critic Agent tarafÄ±ndan denetlenir
    â€¢	â€œBilmiyorumâ€ tamamen serbest

Kabul Kriteri
â€¢ AynÄ± input â†’ farklÄ± ama tutarlÄ± hipotezler Ã¼retilebiliyor.

â¸»

ğŸ§ª Milestone A4 â€” Adversarial Toy Benchmark

AmaÃ§

GerÃ§ekten semantic reasoning test etmek.

Task Ã¶zellikleri
â€¢ misleading coverage
â€¢ state-dependent bug
â€¢ test doÄŸru, sebep dolaylÄ±
â€¢ â€œÃ¶nemsiz gÃ¶rÃ¼nen satÄ±râ€ asÄ±l neden

Her task:
â€¢ failing test
â€¢ ham coverage
â€¢ LLM iÃ§in kasÄ±tlÄ± belirsizlik

Ã‡Ä±ktÄ±lar
â€¢ evaluation/tasks/
â€¢ metadata.json

Kabul Kriteri
â€¢ Coverageâ€™a bakarak yanlÄ±ÅŸ yola sapÄ±labilen taskâ€™lar var.

â¸»

âš™ï¸ Milestone A5 â€” Fully Agentic Run Engine

AmaÃ§

Baseline vs Agentic aynÄ± altyapÄ±, farklÄ± zeka.

Modlar
â€¢ Baseline
â€¢ Tek LLM
â€¢ ReAct benzeri
â€¢ No critic, no reflection
â€¢ Agentic
â€¢ Full agent graph

Her run:
â€¢ tÃ¼m agent mesajlarÄ±
â€¢ tool Ã§aÄŸrÄ±larÄ±
â€¢ reflection kararlarÄ±

Ã‡Ä±ktÄ±lar
â€¢ evaluation/run_all.py
â€¢ runs/<task>/<run_id>/

Kabul Kriteri
â€¢ Tek komutla tÃ¼m deney seti koÅŸuyor.

â¸»

ğŸ“Š Milestone A6 â€” LLM-Based Evaluation (No Hard Metrics)

AmaÃ§

â€œDoÄŸru / yanlÄ±ÅŸâ€ bile LLM tarafÄ±ndan yorumlansÄ±n.

Evaluation Agent

Input:
â€¢ full run log
â€¢ final outcome

Soru seti:
â€¢ â€œAjan makul mÃ¼ davrandÄ±?â€
â€¢ â€œYanlÄ±ÅŸ ama Ã¶zgÃ¼venli miydi?â€
â€¢ â€œNe zaman durmalÄ±ydÄ±?â€

Ã‡Ä±ktÄ±:

{
"behavior": "reasonable|confused|overconfident",
"failure_type": "...",
"commentary": "..."
}

Kod:
â€¢ sadece sayar
â€¢ istatistik Ã§Ä±karÄ±r

Kabul Kriteri
â€¢ Negatif sonuÃ§lar anlamlÄ± anlatÄ± Ã¼retiyor.

â¸»

ğŸ“ Milestone A7 â€” Writing & Defense

Ana vurgu
â€¢ Bu bir baÅŸarÄ± optimizasyonu Ã§alÄ±ÅŸmasÄ± deÄŸil
â€¢ Bu bir sÄ±nÄ±r keÅŸfi Ã§alÄ±ÅŸmasÄ±

Paper baÅŸlÄ±ÄŸÄ± Ã¶nerisi:

When LLMs Are Left Alone: An Agentic Study of Semantic Interpretation Without Hand-Coded Control

Threats to Validity
â€¢ model baÄŸÄ±mlÄ±lÄ±ÄŸÄ±
â€¢ prompt sensitivity
â€¢ LLM-as-judge riski (bilinÃ§li olarak kabul)
